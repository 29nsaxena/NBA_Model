{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "527b5b63-020e-407e-a064-dfcf39b4f6db",
      "cell_type": "code",
      "source": "# generate_players_json.py\n# Run this script in JupyterLite (with the CSVs) to generate players.json\n# Then deploy nbav1.py + players.json to Render/Railway\n\n\nimport pandas as pd\nimport json\n\n\n\n\n# Load the datasets\ndf = pd.read_csv(\"NBA_Data.csv\")  # Main player statistics data\ndf_averages = pd.read_csv(\"U_Averages.csv\")  # Player averages data\ndf_names = pd.read_csv(\"Names.csv\")  # NBA player IDs and names\n\n\n\n\n# Define the skill columns to analyze\nskills = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n\n\n\n\n# Remove any leading/trailing whitespace from column names\ndf.columns = df.columns.str.strip()\ndf_averages.columns = df_averages.columns.str.strip()\ndf_names.columns = df_names.columns.str.strip()\n\n\n\n\n# Remove header rows from dataframes (rows 0 and 1 contain metadata/headers)\ndf = df.iloc[1:]\ndf_averages = df_averages.iloc[1:]\n\n\n\n\n# CRITICAL: Normalize Player_IDs immediately after loading\n# Convert numeric-looking IDs to integers, then to strings (removes trailing .0)\ndf[\"Player_ID\"] = (\n    pd.to_numeric(df[\"Player_ID\"], errors=\"coerce\")\n    .astype(\"Int64\")\n    .astype(str)\n    .str.strip()\n)\ndf_averages[\"Player_ID\"] = (\n    pd.to_numeric(df_averages[\"Player_ID\"], errors=\"coerce\")\n    .astype(\"Int64\")\n    .astype(str)\n    .str.strip()\n)\ndf_names[\"Player_ID\"] = (\n    pd.to_numeric(df_names[\"Player_ID\"], errors=\"coerce\")\n    .fillna(0)\n    .astype(\"Int64\")\n    .astype(str)\n    .str.strip()\n)\n\n\n\n\n# Convert skill columns to numeric\nfor skill in skills:\n    df[skill] = pd.to_numeric(df[skill], errors=\"coerce\")\n\n\n\n\n# Reset index after slicing to avoid alignment issues\ndf = df.reset_index(drop=True)\ndf_averages = df_averages.reset_index(drop=True)\n\n\n\n\n# Calculate z-scores manually (no sklearn needed)\n# z-score = (value - mean) / std\nfor skill in skills:\n    mean = df[skill].mean()\n    std = df[skill].std()\n    if std > 0:\n        df[skill + \"_z\"] = (df[skill] - mean) / std\n    else:\n        df[skill + \"_z\"] = 0\n\n\n\n\n# Get list of all z-score column names\nz_cols = [c for c in df.columns if c.endswith(\"_z\")]\n\n\n\n\n# Remove rows where all z-scores are missing (invalid players)\ndf = df.dropna(subset=z_cols, how=\"all\")\n\n\n\n\n# Find each player's best skill (highest z-score) and remove the \"_z\" suffix\ndf[\"best_skill\"] = (\n    df[z_cols]\n    .idxmax(axis=1, skipna=True)  # Find column with max value for each row\n    .str.replace(\"_z\", \"\")  # Remove suffix to get original skill name\n)\n\n\n\n\n# Store the actual z-score value of the best skill\ndf[\"best_score\"] = df[z_cols].max(axis=1, skipna=True)\n\n\n\n\n# Merge main data with averages data to get raw skill values\nmerged = df.merge(df_averages, on=\"Player_ID\", suffixes=(\"\", \"_raw\"))\n\n\n\n\n# For each player, extract the raw value of their best skill\nmerged[\"best_skill_raw_value\"] = merged.apply(\n    lambda row: row[row[\"best_skill\"]],  # Use best_skill name to lookup its raw value\n    axis=1\n)\n\n\n\n\n# Merge the dataframes on Player_ID\nfinal_df = merged.merge(\n    df_names[['Player_ID', 'Name']],\n    on='Player_ID',\n    how='left'  # Keep all players even if name not found\n)\n\n\n\n\n# Show merge statistics\nprint(\"MERGE DIAGNOSTICS:\")\nprint(f\"Players in final dataset: {len(final_df)}\")\nprint(f\"Players with names: {final_df['Name'].notna().sum()}\")\nprint(f\"Players without names: {final_df['Name'].isna().sum()}\")\n\n\n\n\n# Verify LeBron is there\nlebron_check = final_df[final_df['Name'].str.contains('LeBron', case=False, na=False)]\nif len(lebron_check) > 0:\n    print(f\"\\n✓ LeBron James found in final dataset!\")\nelse:\n    print(f\"\\n✗ LeBron James NOT in final dataset\")\n    lebron_in_names = df_names[df_names['Name'].str.contains('LeBron', case=False, na=False)]\n    if len(lebron_in_names) > 0:\n        lebron_id = lebron_in_names['Player_ID'].values[0]\n        print(f\"   LeBron's Player_ID in Names.csv: {lebron_id}\")\n        print(f\"   Is this ID in NBA_Data? {lebron_id in df['Player_ID'].values}\")\n\n\n\n\nprint(\"\\n\" + \"=\"*60)\n\n\n\n\n# Export to JSON for the FastAPI app\noutput = final_df[['Player_ID', 'Name', 'best_skill', 'best_score', 'best_skill_raw_value']].copy()\noutput.columns = ['player_id', 'name', 'best_skill', 'z_score', 'raw_value']\n\n\n# Round z_score to 3 decimal places for cleaner output\noutput['z_score'] = output['z_score'].round(3)\n\n\n# Convert to list of dictionaries and save as JSON\nplayers_list = output.to_dict(orient='records')\n\n\nwith open('players.json', 'w') as f:\n    json.dump(players_list, f, indent=2)\n\n\nprint(f\"\\n✓ Exported {len(players_list)} players to players.json\")\nprint(\"\\nNext steps:\")\nprint(\"1. Copy players.json to your deployment folder\")\nprint(\"2. Deploy nbav1.py + players.json to Render/Railway\")\n",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "MERGE DIAGNOSTICS:\nPlayers in final dataset: 567\nPlayers with names: 229\nPlayers without names: 338\n\n✓ LeBron James found in final dataset!\n\n============================================================\n"
        }
      ],
      "execution_count": null
    },
    {
      "id": "d934e880-15e3-46cb-9850-a93274e180d4",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "835e71f7-c5cc-4238-bac6-322ffbc2e768",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}